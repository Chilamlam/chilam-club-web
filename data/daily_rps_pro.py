import tushare as ts
import pandas as pd
import datetime
import os
import time

# ================= é…ç½®åŒº =================
# ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼ï¼šä»ç¯å¢ƒå˜é‡è·å– Token
MY_TOKEN = '1dc4825f1b185ab6efdacb1cfff887696c6bbcce2e5c547bfa270b56'

RPS_N = [50, 120, 250] 
# ä¸ªè‚¡é˜ˆå€¼
STOCK_THRESHOLD = 87
# ETF é˜ˆå€¼ (ETF æ³¢åŠ¨å°ï¼Œåˆ†æ•°å¯ä»¥ç¨å¾®æ”¾å®½ï¼Œæˆ–è€…ä¿æŒä¸€è‡´)
ETF_THRESHOLD = 80 

STOCK_PATH = "data/strong_stocks.csv"
ETF_PATH = "data/strong_etfs.csv"

# åˆå§‹åŒ–
try:
    if MY_TOKEN:
        ts.set_token(MY_TOKEN)
        pro = ts.pro_api()
    else:
        print("âš ï¸ æç¤ºï¼šæœ¬åœ°è¿è¡Œè¯·æ‰‹åŠ¨é…ç½® Tokenã€‚")
        pro = ts.pro_api('') 
except Exception as e:
    print(f"âŒ Token è®¾ç½®å¼‚å¸¸: {e}")

# ================= é€šç”¨å·¥å…·å‡½æ•° =================

def get_trading_dates(end_date):
    """è·å–æ—¶é—´é”šç‚¹"""
    print("ğŸ“… æ­£åœ¨è®¡ç®—äº¤æ˜“æ—¥æœŸ...")
    start_date = (datetime.datetime.now() - datetime.timedelta(days=400)).strftime('%Y%m%d')
    try:
        df = pro.trade_cal(exchange='', is_open='1', end_date=end_date, start_date=start_date)
        df = df.sort_values('cal_date', ascending=False).reset_index(drop=True)
        if df.empty: return None
        dates = {'now': df.loc[0, 'cal_date']}
        for n in RPS_N:
            if len(df) > n:
                dates[n] = df.loc[n, 'cal_date']
        return dates
    except Exception as e:
        print(f"âŒ è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
        return None

def get_snapshot(code_list, date_str, asset_type='stock'):
    """
    é€šç”¨è·å–è¡Œæƒ…å‡½æ•°
    asset_type: 'stock' æˆ– 'fund'
    """
    try:
        # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œç›´æ¥è¿”å›
        if not code_list: return pd.DataFrame()

        # åˆ†æ‰¹è·å–ï¼Œé˜²æ­¢ URL è¶…é•¿
        # Tushare å•æ¬¡æ”¯æŒ 100-500 ä¸ªä»£ç ï¼Œæˆ‘ä»¬ç¨³å¦¥ç‚¹ç”¨ 100
        chunk_size = 100
        all_dfs = []
        
        for i in range(0, len(code_list), chunk_size):
            chunk = code_list[i:i+chunk_size]
            codes_str = ",".join(chunk)
            
            if asset_type == 'stock':
                df_daily = pro.daily(ts_code=codes_str, trade_date=date_str, fields='ts_code,close')
                df_adj = pro.adj_factor(ts_code=codes_str, trade_date=date_str, fields='ts_code,adj_factor')
                if df_daily.empty or df_adj.empty: continue
                df = pd.merge(df_daily, df_adj, on='ts_code')
                df['close_val'] = df['close'] * df['adj_factor']
                df['display_val'] = df['close']
            else:
                # åŸºé‡‘/ETF æ¨¡å¼ (fund_daily éœ€è¦ç§¯åˆ† 2000+)
                df = pro.fund_daily(ts_code=codes_str, trade_date=date_str, fields='ts_code,close')
                if df.empty: continue
                # ETF å¤æƒæ¯”è¾ƒå¤æ‚ï¼Œé€šå¸¸ç”¨ adj_factor (éœ€ 5000 ç§¯åˆ†) æˆ–ç›´æ¥ç”¨æœªå¤æƒè¿‘ä¼¼
                # ä½ çš„ 2100 ç§¯åˆ†å¯èƒ½æ‹¿ä¸åˆ° fund_adjï¼Œè¿™é‡Œæš‚æ—¶ç”¨æœªå¤æƒä»·æ ¼è®¡ç®— RPS
                # å¯¹äºçŸ­æœŸ(50/120) ETF æ¥è¯´ï¼Œæœªå¤æƒè¯¯å·®é€šå¸¸å¯æ¥å—
                df['close_val'] = df['close'] 
                df['display_val'] = df['close']
            
            all_dfs.append(df)
            
        if not all_dfs: return pd.DataFrame()
        return pd.concat(all_dfs)[['ts_code', 'close_val', 'display_val']]

    except Exception as e:
        print(f"Error fetching {date_str} for {asset_type}: {e}")
        return pd.DataFrame()

def calculate_rps_core(target_codes, dates, asset_type='stock'):
    """æ ¸å¿ƒ RPS è®¡ç®—é€»è¾‘ (ä¼ å…¥ç›®æ ‡ä»£ç åˆ—è¡¨)"""
    # 1. è·å–ä»Šæ—¥æ•°æ®
    df_now = get_snapshot(target_codes, dates['now'], asset_type)
    if df_now.empty: return None
    df_now.rename(columns={'close_val': 'base_now', 'display_val': 'price_now'}, inplace=True)
    
    final_df = df_now.copy()
    
    # 2. å¾ªç¯è®¡ç®—æ¶¨å¹…
    for n in RPS_N:
        if n not in dates: continue
        print(f"   è®¡ç®— RPS_{n} (å¯¹æ¯”æ—¥æœŸ: {dates[n]})...")
        df_past = get_snapshot(target_codes, dates[n], asset_type)
        if df_past.empty: continue
        df_past = df_past[['ts_code', 'close_val']].rename(columns={'close_val': 'base_past'})
        
        temp = pd.merge(final_df, df_past, on='ts_code', how='left')
        temp[f'pct_{n}'] = (temp['base_now'] - temp['base_past']) / temp['base_past']
        # æ³¨æ„ï¼šè¿™é‡Œæ˜¯åœ¨â€œä¼ å…¥çš„è¿™ä¸ªæ± å­â€é‡Œæ’åã€‚
        # å¦‚æœæ˜¯å…¨å¸‚åœºä¸ªè‚¡ï¼Œå°±æ˜¯å…¨å¸‚åœºæ’åã€‚å¦‚æœæ˜¯ Top100 ETFï¼Œå°±æ˜¯è¿™ 100 ä¸ªé‡Œçš„ç›¸å¯¹å¼ºå¼±ã€‚
        temp[f'RPS_{n}'] = temp[f'pct_{n}'].rank(pct=True) * 100
        final_df = temp.drop(columns=['base_past'])
        
    return final_df

def process_history(new_df, file_path, date_str):
    """å¤„ç†è¿ç»­ä¸Šæ¦œå†å²"""
    history_map = {}
    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path)
            for _, row in old_df.iterrows():
                history_map[row['ts_code']] = {
                    'first': row.get('åˆæ¬¡å…¥é€‰', date_str),
                    'days': row.get('è¿ç»­å¤©æ•°', 0),
                    'last_update': row.get('æ›´æ–°æ—¥æœŸ', '')
                }
        except: pass

    res = []
    for _, row in new_df.iterrows():
        code = row['ts_code']
        first_date = date_str
        days_count = 1
        
        if code in history_map:
            hist = history_map[code]
            if hist['last_update'] == date_str:
                days_count = hist['days']
                first_date = hist['first']
            else:
                days_count = hist['days'] + 1
                first_date = hist['first']
        
        row['åˆæ¬¡å…¥é€‰'] = first_date
        row['è¿ç»­å¤©æ•°'] = days_count
        
        # é“¾æ¥ç”Ÿæˆ
        if '.' in code:
            num, suffix = code.split('.')
            link_code = suffix.lower() + num
            row['eastmoney_url'] = f"https://quote.eastmoney.com/{link_code}.html"
        else:
            row['eastmoney_url'] = ""
            
        res.append(row)
    return pd.DataFrame(res)

# ================= ç‰¹æ®Šé€»è¾‘ï¼šç­›é€‰ Top 100 ETF =================
def get_top_etfs_by_turnover(date_str):
    """è·å–å½“æ—¥æˆäº¤é¢å‰ 100 çš„éè´§å¸ ETF"""
    print("ğŸ” æ­£åœ¨ç­›é€‰å…¨å¸‚åœºæˆäº¤é¢ Top 100 ETF...")
    try:
        # 1. è·å– ETF åˆ—è¡¨ (market='E')
        # ä½ çš„ 2100 ç§¯åˆ†å¯ä»¥è°ƒå– fund_basic
        basic = pro.fund_basic(market='E', status='L', fields='ts_code,name,fund_type')
        
        # è¿‡æ»¤æ‰ 'è´§å¸å¸‚åœºå‹'ï¼Œåªä¿ç•™ è‚¡ç¥¨å‹ã€å€ºåˆ¸å‹ã€å•†å“å‹ã€QDII
        # ç›®çš„ï¼šæˆ‘ä»¬ä¸éœ€è¦çœ‹ä½™é¢å®ä¹‹ç±»çš„ RPS
        mask_type = ~basic['fund_type'].str.contains('è´§å¸')
        valid_etfs = basic[mask_type]
        valid_codes = valid_etfs['ts_code'].tolist()
        
        print(f"   å…¨å¸‚åœºéè´§å¸ ETF å…± {len(valid_codes)} åªï¼Œæ­£åœ¨è·å–è¡Œæƒ…æ’å...")
        
        # 2. è·å–ä»Šæ—¥è¡Œæƒ… (æŒ‰æˆäº¤é¢æ’åº)
        # fund_daily å¦‚æœä¸ä¼  ts_codeï¼Œé»˜è®¤å¯èƒ½åªè¿”å›éƒ¨åˆ†æˆ–é™åˆ¶ï¼Œå»ºè®®ä¼ å…¥ list
        # è¿™é‡Œä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬åˆ†æ‰¹è·å–æ‰€æœ‰ ETF çš„ amountï¼Œç„¶åè‡ªå·±æ’åº
        # æ³¨æ„ï¼šè¿™æ­¥å¯èƒ½ç¨å¾®èŠ±ç‚¹æ—¶é—´ï¼Œä½†æœ€å‡†ç¡®
        
        # ä¼˜åŒ–ç­–ç•¥ï¼šå¦‚æœç§¯åˆ†å…è®¸ï¼Œç›´æ¥è¯·æ±‚ trade_date
        # å°è¯•ç›´æ¥è¯·æ±‚å…¨é‡ï¼Œå¦‚æœæŠ¥é”™å†æ”¹åˆ†æ‰¹
        df_daily = pro.fund_daily(trade_date=date_str, fields='ts_code,amount,close')
        
        # è¿‡æ»¤å‡ºåˆšæ‰ç­›é€‰çš„é‚£äº›éè´§å¸ ETF
        df_target = df_daily[df_daily['ts_code'].isin(valid_codes)].copy()
        
        # æŒ‰æˆäº¤é¢ (amount) é™åºæ’åˆ—
        # amount å•ä½é€šå¸¸æ˜¯ åƒå…ƒ
        df_top100 = df_target.sort_values('amount', ascending=False).head(100)
        
        # åˆå¹¶åç§°
        df_final = pd.merge(df_top100, valid_etfs[['ts_code', 'name', 'fund_type']], on='ts_code')
        
        # æŠŠæˆäº¤é¢æ¢ç®—æˆ "äº¿"
        df_final['amount_äº¿'] = df_final['amount'] / 10000 / 10000 * 1000 # amountæ˜¯åƒå…ƒ -> *1000=å…ƒ -> /1e8 = äº¿
        
        print(f"   âœ… å·²é”å®š Top 100 ETFï¼Œé—¨æ§›æˆäº¤é¢: {df_final['amount_äº¿'].iloc[-1]:.2f} äº¿")
        return df_final
        
    except Exception as e:
        print(f"âŒ ç­›é€‰ ETF å¤±è´¥: {e}")
        return pd.DataFrame()

# ================= ä¸»ä»»åŠ¡ =================
def main_job():
    print("ğŸš€ å¯åŠ¨å…¨å¸‚åœºæ‰«æ (è‚¡ç¥¨ + Top100 ETF)...")
    today_str = datetime.datetime.now().strftime('%Y%m%d')
    today_fmt = datetime.datetime.now().strftime('%Y-%m-%d')
    
    # æœ¬åœ°æµ‹è¯•
    # today_str = '20260123' 

    if not MY_TOKEN:
        print("âš ï¸ è­¦å‘Šï¼šç¯å¢ƒå˜é‡ä¸­æœªæ£€æµ‹åˆ° Token")

    dates = get_trading_dates(today_str)
    if not dates: 
        print("âŒ éäº¤æ˜“æ—¥æˆ–æ— æ³•è·å–æ—¥å†ï¼Œç¨‹åºç»“æŸ")
        return
    
    os.makedirs("data", exist_ok=True)

    # ----------------------------------------------------
    # ä»»åŠ¡ 1ï¼šä¸ªè‚¡ RPS (å…¨å¸‚åœºæ‰«æ)
    # ----------------------------------------------------
    print("\n=== æ­£åœ¨å¤„ç† [ä¸ªè‚¡] RPS ===")
    try:
        # è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
        stk_basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
        all_stocks = stk_basic['ts_code'].tolist()
        
        # è®¡ç®—
        df_stock = calculate_rps_core(all_stocks, dates, asset_type='stock')
        
        if df_stock is not None:
            df_stock = pd.merge(df_stock, stk_basic, on='ts_code', how='left')
            # ç­›é€‰
            mask = (df_stock['RPS_50'] > STOCK_THRESHOLD) & (df_stock['RPS_120'] > STOCK_THRESHOLD) & (df_stock['RPS_250'] > STOCK_THRESHOLD)
            strong_stock = df_stock[mask].copy()
            strong_stock['æ›´æ–°æ—¥æœŸ'] = today_fmt
            
            # å†å²
            final_stock = process_history(strong_stock, STOCK_PATH, today_fmt)
            
            # ä¿å­˜
            cols = ['ts_code', 'name', 'industry', 'price_now', 'RPS_50', 'RPS_120', 'RPS_250', 'è¿ç»­å¤©æ•°', 'åˆæ¬¡å…¥é€‰', 'eastmoney_url', 'æ›´æ–°æ—¥æœŸ']
            final_stock[cols].round(2).to_csv(STOCK_PATH, index=False)
            print(f"âœ… ä¸ªè‚¡æ›´æ–°å®Œæˆ: {len(final_stock)} åª")
    except Exception as e:
        print(f"âŒ ä¸ªè‚¡ä»»åŠ¡å‡ºé”™: {e}")

    # ----------------------------------------------------
    # ä»»åŠ¡ 2ï¼šTop 100 ETF RPS
    # ----------------------------------------------------
    print("\n=== æ­£åœ¨å¤„ç† [ETF] RPS ===")
    try:
        # 1. å…ˆé€‰å‡º Top 100
        top_etf_info = get_top_etfs_by_turnover(dates['now'])
        
        if not top_etf_info.empty:
            target_etfs = top_etf_info['ts_code'].tolist()
            
            # 2. è®¡ç®—è¿™ 100 ä¸ªçš„ RPS
            df_etf_rps = calculate_rps_core(target_etfs, dates, asset_type='fund')
            
            if df_etf_rps is not None:
                # åˆå¹¶ä¿¡æ¯ (åç§°ã€æˆäº¤é¢ã€ç±»å‹)
                df_etf = pd.merge(df_etf_rps, top_etf_info, on='ts_code', how='inner')
                
                # ç­›é€‰ (ETF å¯ä»¥å…¨å±•ç¤ºï¼Œæˆ–è€…åªå±•ç¤º RPS é«˜çš„)
                # è¿™é‡Œæˆ‘ä»¬å…¨éƒ¨ä¿ç•™ï¼ŒæŒ‰ RPS æ’åºï¼Œæ–¹ä¾¿è§‚å¯Ÿ
                df_etf['æ›´æ–°æ—¥æœŸ'] = today_fmt
                
                # å†å²å¤„ç†
                final_etf = process_history(df_etf, ETF_PATH, today_fmt)
                
                # ä¿å­˜
                cols_etf = ['ts_code', 'name', 'fund_type', 'amount_äº¿', 'price_now', 'RPS_50', 'RPS_120', 'è¿ç»­å¤©æ•°', 'eastmoney_url', 'æ›´æ–°æ—¥æœŸ']
                final_etf[cols_etf].round(2).to_csv(ETF_PATH, index=False)
                print(f"âœ… ETF æ›´æ–°å®Œæˆ: {len(final_etf)} åª (Top 100 æ´»è·ƒ)")
        else:
            print("âš ï¸ æœªèƒ½ç­›é€‰å‡º ETF")
            
    except Exception as e:
        print(f"âŒ ETF ä»»åŠ¡å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main_job()
