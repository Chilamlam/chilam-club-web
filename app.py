import streamlit as st
import pandas as pd
from langchain_openai import ChatOpenAI
# ğŸ‘‡ ä¿®æ”¹äº†ä¸‹é¢è¿™è¡Œï¼Œæ”¹ç”¨ langchain_core
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import akshare as st_ak

# ================= é…ç½®éƒ¨åˆ† =================
st.set_page_config(
    page_title="Chilam Club - AI è´¢ç»ç»ˆç«¯",
    page_icon="ğŸ“°",
    layout="wide"
)

# ================= æ•°æ®è·å–å±‚ =================
@st.cache_data(ttl=300) # å¢åŠ ç¼“å­˜ï¼Œæ¯5åˆ†é’Ÿæ‰æ‹‰ä¸€æ¬¡æ–°æ•°æ®ï¼Œé˜²æ­¢è¢«å°IP
def get_news_data():
    try:
        # å°è¯•è·å–å…¨çƒè´¢ç»æ–°é—»
        df = st_ak.stock_info_global_cls()
        return df
    except Exception as e:
        st.error(f"æ•°æ®æºæš‚æ—¶ä¸å¯ç”¨ï¼Œæ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
        # å¦‚æœ Akshare å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿæ•°æ®é˜²æ­¢ç¨‹åºå´©æºƒ
        mock_data = {
            "æ ‡é¢˜": ["æµ‹è¯•æ–°é—»ï¼šæŸç§‘æŠ€å·¨å¤´å‘å¸ƒæ–°ä¸€ä»£AIèŠ¯ç‰‡", "æµ‹è¯•æ–°é—»ï¼šæ–°èƒ½æºæ±½è½¦é”€é‡å¤§æ¶¨"],
            "å‘å¸ƒæ—¥æœŸ": ["2026-01-24", "2026-01-24"],
            "å‘å¸ƒæ—¶é—´": ["10:00:00", "11:30:00"],
            "å†…å®¹": ["æŸå…¬å¸ä»Šæ—¥å‘å¸ƒäº†æœ€æ–°ä¸€ä»£GPUï¼Œç®—åŠ›æå‡30%...", "ä¹˜è”ä¼šæ•°æ®æ˜¾ç¤ºï¼Œæœ¬æœˆæ–°èƒ½æºè½¦æ¸—é€ç‡çªç ´50%..."]
        }
        return pd.DataFrame(mock_data)

def app():
    # ================= ç•Œé¢å¸ƒå±€ =================
    st.title("ğŸ¤– æ–°é—»æ¦‚å¿µæŒ–æ˜[å…è´¹æœåŠ¡5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡]")
    st.caption("Powered by Chilam Club")

    # ================= å®‰å…¨è·å– API Key =================
    # ä» Streamlit Secrets è·å– Keyï¼Œä¸å†ç¡¬ç¼–ç 
    if "ZHIPU_API_KEY" in st.secrets:
        api_key = st.secrets["ZHIPU_API_KEY"]
    else:
        st.error("è¯·åœ¨ Streamlit åå° Settings -> Secrets ä¸­é…ç½® ZHIPU_API_KEY")
        st.stop()

    # ================= ä¸»ç¨‹åºé€»è¾‘ =================
    # åŠ è½½æ•°æ®
    with st.spinner('æ­£åœ¨è¿æ¥å…¨çƒè´¢ç»èµ„è®¯...'):
        news_df = get_news_data()

    # åˆå§‹åŒ– Session State ç”¨äºå­˜å‚¨é€‰ä¸­çš„æ–°é—»
    if 'selected_idx' not in st.session_state:
        st.session_state.selected_idx = 0

    # å¸ƒå±€ï¼šå·¦ä¾§æ–°é—»åˆ—è¡¨ï¼Œå³ä¾§è¯¦æƒ…ä¸åˆ†æ
    col_list, col_detail = st.columns([3, 7])

    with col_list:
        st.subheader("ğŸ“° å®æ—¶æ–°é—»æµ")
        # æ˜¾ç¤ºæ–°é—»åˆ—è¡¨
        for idx, row in news_df.iterrows():
            with st.container():
                # é«˜äº®é€‰ä¸­é¡¹
                if idx == st.session_state.selected_idx:
                    status = "primary" # é€‰ä¸­çŠ¶æ€é¢œè‰²
                else:
                    status = "secondary" # æ™®é€šçŠ¶æ€
                
                # ç‚¹å‡»äº‹ä»¶
                btn_label = f"{row['æ ‡é¢˜'][:15]}..." # ç¼©çŸ­æ ‡é¢˜é˜²æ­¢å¤ªé•¿
                if st.button(
                    f"ğŸ“„ {row['æ ‡é¢˜']}", 
                    key=f"news_{idx}", 
                    use_container_width=True,
                    type=status
                ):
                    st.session_state.selected_idx = idx
                    st.rerun()

    with col_detail:
        # è·å–å½“å‰é€‰ä¸­çš„æ–°é—»
        if not news_df.empty:
            current_news = news_df.iloc[st.session_state.selected_idx]
            
            st.markdown("---")
            # 1. å±•ç¤ºæ–°é—»åŸæ–‡
            st.subheader(f"ğŸ“Œ {current_news['æ ‡é¢˜']}")
            st.caption(f"å‘å¸ƒæ—¶é—´ï¼š{current_news['å‘å¸ƒæ—¥æœŸ']} {current_news['å‘å¸ƒæ—¶é—´']}")
            st.info(current_news['å†…å®¹'])

            # 2. AI åˆ†ææŒ‰é’®
            st.markdown("### ğŸ§  AI æ·±åº¦åˆ†æ")
            if st.button("âœ¨ å¼€å§‹åˆ†æï¼šæå–æ¦‚å¿µ & æŒ–æ˜ä¸ªè‚¡", type="primary"):
                with st.spinner("AI åˆ†æå¸ˆæ­£åœ¨é˜…è¯»æ–°é—»å¹¶è¿›è¡Œé€»è¾‘æ¨ç†..."):
                    try:
                        # åˆå§‹åŒ– LLM (æ™ºè°±AI)
                        llm = ChatOpenAI(
                            api_key=api_key,
                            base_url="https://open.bigmodel.cn/api/paas/v4/",
                            model="glm-4-flash",
                            temperature=0.3
                        )

                        # æ„å»º Prompt
                        prompt = ChatPromptTemplate.from_messages([
                            ("system", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»è¯åˆ¸åˆ†æå¸ˆã€‚è¯·é˜…è¯»ç”¨æˆ·æä¾›çš„è´¢ç»æ–°é—»ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n"
                                     "0. **æƒ…ç»ªè¯†åˆ«**ï¼šåˆ†æè¯¥æ–°é—»çš„å†…å®¹åˆ°åº•æ˜¯åˆ©å¥½è¿˜æ˜¯åˆ©ç©ºã€‚\n"
                                     "1. **æ¦‚å¿µè¯†åˆ«**ï¼šåˆ†æè¯¥æ–°é—»æ¶‰åŠçš„æ ¸å¿ƒäº§ä¸šé“¾æ¦‚å¿µï¼ˆä¾‹å¦‚ï¼šRobotaxi, CPO, åˆ›æ–°è¯ç­‰ï¼‰ã€‚\n"
                                     "2. **ä¸ªè‚¡æŒ–æ˜**ï¼šæ ¹æ®æ¦‚å¿µï¼Œåˆ—å‡º3-5åªAè‚¡æˆ–æ¸¯è‚¡ä¸­æœ€ç›¸å…³çš„é¾™å¤´ä¸ªè‚¡åç§°ï¼Œå¹¶ç”¨ä¸€å¥è¯è§£é‡Šå…³è”ç†ç”±ã€‚\n\n"
                                     "è¾“å‡ºæ ¼å¼è¯·ä½¿ç”¨ Markdownï¼Œæ¸…æ™°åˆ†çº§ã€‚"),
                            ("user", "æ–°é—»æ ‡é¢˜ï¼š{title}\n\næ–°é—»å†…å®¹ï¼š{content}\n\nè¯·å¼€å§‹åˆ†æã€‚")
                        ])

                        chain = prompt | llm | StrOutputParser()

                        # è°ƒç”¨æ¨¡å‹
                        analysis_result = chain.invoke({
                            "title": current_news['æ ‡é¢˜'],
                            "content": current_news['å†…å®¹']
                        })

                        # å±•ç¤ºç»“æœ
                        st.success("åˆ†æå®Œæˆï¼")
                        st.markdown(analysis_result)

                    except Exception as e:
                        st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        else:
            st.warning("æš‚æ— æ–°é—»æ•°æ®")

if __name__ == "__main__":
    app()


