import tushare as ts
import pandas as pd
import datetime
import os

# ================= é…ç½®åŒº =================
# ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼ï¼šä»ç¯å¢ƒå˜é‡è·å– Token
MY_TOKEN = os.getenv('TUSHARE_TOKEN')

RPS_N = [50, 120, 250] 
THRESHOLD = 87
STOCK_PATH = "data/strong_stocks.csv"

# åˆå§‹åŒ–
try:
    if MY_TOKEN:
        ts.set_token(MY_TOKEN)
        pro = ts.pro_api()
    else:
        print("âš ï¸ æç¤ºï¼šæœ¬åœ°è¿è¡Œè¯·æ‰‹åŠ¨é…ç½® Token")
        pro = ts.pro_api('') 
except Exception as e:
    print(f"âŒ Token è®¾ç½®å¼‚å¸¸: {e}")

def get_trading_dates(end_date):
    """è·å–æ—¶é—´é”šç‚¹"""
    print("ğŸ“… æ­£åœ¨è®¡ç®—äº¤æ˜“æ—¥æœŸ...")
    start_date = (datetime.datetime.now() - datetime.timedelta(days=400)).strftime('%Y%m%d')
    try:
        df = pro.trade_cal(exchange='', is_open='1', end_date=end_date, start_date=start_date)
        df = df.sort_values('cal_date', ascending=False).reset_index(drop=True)
        if df.empty: return None
        dates = {'now': df.loc[0, 'cal_date']}
        for n in RPS_N:
            if len(df) > n:
                dates[n] = df.loc[n, 'cal_date']
        return dates
    except Exception as e:
        print(f"âŒ è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
        return None

def get_snapshot(date_str):
    """è·å–ä¸ªè‚¡è¡Œæƒ…ï¼ˆä»·æ ¼ï¼‰"""
    print(f"   æ­£åœ¨è·å– {date_str} çš„ä»·æ ¼æ•°æ®...")
    try:
        df_daily = pro.daily(trade_date=date_str, fields='ts_code,close')
        df_adj = pro.adj_factor(trade_date=date_str, fields='ts_code,adj_factor')
        
        if df_daily.empty or df_adj.empty: return pd.DataFrame()
        
        df = pd.merge(df_daily, df_adj, on='ts_code')
        df['close_val'] = df['close'] * df['adj_factor'] 
        df['display_val'] = df['close'] 
        return df[['ts_code', 'close_val', 'display_val']]
    except Exception as e:
        print(f"Error: {e}")
        return pd.DataFrame()

def get_fundamental_data(date_str):
    """
    â˜… æ–°å¢åŠŸèƒ½ï¼šè·å–åŸºæœ¬é¢æŒ‡æ ‡ (2100ç§¯åˆ†ä¸“å±)
    åŒ…å«ï¼šå¸‚ç›ˆç‡(TTM)ã€å¸‚å‡€ç‡ã€æ¢æ‰‹ç‡ã€æµé€šå¸‚å€¼
    """
    print(f"ğŸ“Š æ­£åœ¨è·å– {date_str} çš„åŸºæœ¬é¢æ•°æ® (PE/PB/å¸‚å€¼)...")
    try:
        # daily_basic æ¥å£éœ€è¦ 2000 ç§¯åˆ†
        df = pro.daily_basic(trade_date=date_str, 
                             fields='ts_code,turnover_rate,pe_ttm,pb,circ_mv')
        if df.empty:
            print("âš ï¸ æœªè·å–åˆ°åŸºæœ¬é¢æ•°æ® (å¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æƒé™ä¸è¶³)")
            return pd.DataFrame()
        
        # circ_mv å•ä½æ˜¯ä¸‡ï¼Œè½¬æ¢ä¸ºäº¿ï¼Œä¿ç•™2ä½å°æ•°
        df['mv_äº¿'] = (df['circ_mv'] / 10000).round(2)
        
        # å¤„ç†ä¸€ä¸‹ PEï¼Œè´Ÿå€¼é€šå¸¸æ²¡æ„ä¹‰æˆ–äºæŸ
        return df[['ts_code', 'pe_ttm', 'pb', 'turnover_rate', 'mv_äº¿']]
    except Exception as e:
        print(f"âŒ åŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def calculate_rps_logic(dates):
    """æ ¸å¿ƒ RPS è®¡ç®—é€»è¾‘"""
    # 1. è·å–ä»Šæ—¥æ•°æ®
    df_now = get_snapshot(dates['now'])
    if df_now.empty: return None
    df_now.rename(columns={'close_val': 'base_now', 'display_val': 'price_now'}, inplace=True)
    
    # 2. å¾ªç¯è®¡ç®—æ¶¨å¹…
    final_df = df_now.copy()
    for n in RPS_N:
        if n not in dates: continue
        df_past = get_snapshot(dates[n])
        if df_past.empty: continue
        df_past = df_past[['ts_code', 'close_val']].rename(columns={'close_val': 'base_past'})
        
        temp = pd.merge(final_df, df_past, on='ts_code', how='left')
        temp[f'pct_{n}'] = (temp['base_now'] - temp['base_past']) / temp['base_past']
        temp[f'RPS_{n}'] = temp[f'pct_{n}'].rank(pct=True) * 100
        final_df = temp.drop(columns=['base_past'])
        
    return final_df

def process_history(new_df, file_path, date_str):
    """å¤„ç†è¿ç»­ä¸Šæ¦œå†å²"""
    history_map = {}
    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path)
            for _, row in old_df.iterrows():
                history_map[row['ts_code']] = {
                    'first': row.get('åˆæ¬¡å…¥é€‰', date_str),
                    'days': row.get('è¿ç»­å¤©æ•°', 0),
                    'last_update': row.get('æ›´æ–°æ—¥æœŸ', '')
                }
        except: pass

    res = []
    for _, row in new_df.iterrows():
        code = row['ts_code']
        first_date = date_str
        days_count = 1
        
        if code in history_map:
            hist = history_map[code]
            if hist['last_update'] == date_str:
                days_count = hist['days']
                first_date = hist['first']
            else:
                days_count = hist['days'] + 1
                first_date = hist['first']
        
        row['åˆæ¬¡å…¥é€‰'] = first_date
        row['è¿ç»­å¤©æ•°'] = days_count
        
        # é“¾æ¥
        if '.' in code:
            num, suffix = code.split('.')
            link_code = suffix.lower() + num
            row['eastmoney_url'] = f"https://quote.eastmoney.com/{link_code}.html"
        else:
            row['eastmoney_url'] = ""
            
        res.append(row)
    return pd.DataFrame(res)

def main_job():
    print("ğŸš€ å¯åŠ¨ Aè‚¡ RPS + åŸºæœ¬é¢æ·±åº¦æ‰«æ...")
    today_str = datetime.datetime.now().strftime('%Y%m%d')
    today_fmt = datetime.datetime.now().strftime('%Y-%m-%d')
    
    if not MY_TOKEN:
        print("âš ï¸ è­¦å‘Šï¼šç¯å¢ƒå˜é‡ä¸­æœªæ£€æµ‹åˆ° Token")

    dates = get_trading_dates(today_str)
    if not dates: 
        print("âŒ éäº¤æ˜“æ—¥æˆ–æ— æ³•è·å–æ—¥å†ï¼Œç¨‹åºç»“æŸ")
        return
    
    os.makedirs("data", exist_ok=True)

    # 1. è®¡ç®— RPS
    df_stock = calculate_rps_logic(dates)
    
    if df_stock is not None:
        try:
            # 2. è·å–åŸºç¡€ä¿¡æ¯ (åç§°ã€è¡Œä¸š)
            basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
            df_stock = pd.merge(df_stock, basic, on='ts_code', how='left')
            
            # 3. â˜… è·å–åŸºæœ¬é¢æ•°æ® (PE/PB/å¸‚å€¼/æ¢æ‰‹) å¹¶åˆå¹¶
            fina_df = get_fundamental_data(dates['now'])
            if not fina_df.empty:
                df_stock = pd.merge(df_stock, fina_df, on='ts_code', how='left')
            
            # 4. ç­›é€‰å¼ºåŠ¿è‚¡
            mask = (df_stock['RPS_50'] > THRESHOLD) & (df_stock['RPS_120'] > THRESHOLD) & (df_stock['RPS_250'] > THRESHOLD)
            strong_stock = df_stock[mask].copy()
            strong_stock['æ›´æ–°æ—¥æœŸ'] = today_fmt
            
            # 5. å¤„ç†å†å²
            final_stock = process_history(strong_stock, STOCK_PATH, today_fmt)
            
            # 6. ä¿å­˜ (æ–°å¢äº†åŸºæœ¬é¢åˆ—)
            # ç¡®ä¿åˆ—å­˜åœ¨ (é˜²æ­¢ fundamental è·å–å¤±è´¥æŠ¥é”™)
            base_cols = ['ts_code', 'name', 'industry', 'price_now', 'RPS_50', 'RPS_120', 'è¿ç»­å¤©æ•°']
            extra_cols = ['pe_ttm', 'mv_äº¿', 'turnover_rate', 'eastmoney_url', 'æ›´æ–°æ—¥æœŸ']
            
            # åŠ¨æ€æ£€æŸ¥å“ªäº›åˆ—å­˜åœ¨
            save_cols = [c for c in base_cols + extra_cols if c in final_stock.columns]
            
            final_stock[save_cols].round(2).to_csv(STOCK_PATH, index=False)
            print(f"âœ… æˆåŠŸï¼å·²æ›´æ–° {len(final_stock)} åªå¼ºåŠ¿è‚¡ (å«åŸºæœ¬é¢æ•°æ®)")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("âš ï¸ æœªè·å–åˆ°è¡Œæƒ…æ•°æ®")

if __name__ == "__main__":
    main_job()
