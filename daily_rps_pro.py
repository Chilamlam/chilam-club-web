import tushare as ts
import pandas as pd
import datetime
import os
import time
import akshare as ak
import concurrent.futures

# ================= é…ç½®åŒº =================
LOCAL_TOKEN = '' 
MY_TOKEN = os.getenv('TUSHARE_TOKEN', LOCAL_TOKEN)

RPS_N = [50, 120, 250] 
THRESHOLD = 87
STOCK_PATH = "data/strong_stocks.csv"

# åˆå§‹åŒ–
try:
    if MY_TOKEN:
        ts.set_token(MY_TOKEN)
        pro = ts.pro_api()
    else:
        pro = ts.pro_api('')
except Exception as e:
    print(f"âŒ Token è®¾ç½®å¼‚å¸¸: {e}")

# ================= å·¥å…·å‡½æ•° =================

def get_trading_dates(end_date):
    print("ğŸ“… [ä¸ªè‚¡] æ­£åœ¨è·å–äº¤æ˜“æ—¥å†...")
    # å‘å‰å¤šå–ä¸€äº›æ—¥å­ï¼Œç¡®ä¿èƒ½è¦†ç›–åˆ° RPS_N çš„æœ€å¤§å€¼
    start_date = (datetime.datetime.now() - datetime.timedelta(days=400)).strftime('%Y%m%d')
    try:
        # è·å–äº¤æ˜“æ—¥å†
        df = pro.trade_cal(exchange='', is_open='1', end_date=end_date, start_date=start_date)
        df = df.sort_values('cal_date', ascending=False).reset_index(drop=True)
        if df.empty: return None
        
        dates = {
            'now': df.loc[0, 'cal_date'],  # æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥
            'prev': df.loc[1, 'cal_date'] if len(df) > 1 else None
        }
        for n in RPS_N:
            if len(df) > n:
                dates[n] = df.loc[n, 'cal_date']
        return dates
    except Exception as e:
        print(f"âŒ è·å–æ—¥å†å¤±è´¥: {e}")
        return None

def get_snapshot(date_str):
    print(f"   æ­£åœ¨è·å– {date_str} çš„è¡Œæƒ…...")
    try:
        df_daily = pro.daily(trade_date=date_str, fields='ts_code,close')
        df_adj = pro.adj_factor(trade_date=date_str, fields='ts_code,adj_factor')
        
        if df_daily.empty or df_adj.empty: return pd.DataFrame()
        
        df = pd.merge(df_daily, df_adj, on='ts_code')
        df['close_val'] = df['close'] * df['adj_factor'] 
        df['display_val'] = df['close'] 
        
        return df[['ts_code', 'close_val', 'display_val']]
    except Exception as e:
        print(f"Error: {e}")
        return pd.DataFrame()

def get_fundamental_smart(date_str, backup_date_str=None):
    print(f"ğŸ“Š æ­£åœ¨è·å–åŸºæœ¬é¢æ•°æ®...")
    fields = 'ts_code,turnover_rate,pe_ttm,pb,circ_mv'
    df = pro.daily_basic(trade_date=date_str, fields=fields)
    
    if df.empty and backup_date_str:
        print(f"   âš ï¸ {date_str} æ•°æ®æœªå‡ºï¼Œåˆ‡æ¢è‡³æ˜¨æ—¥ {backup_date_str}...")
        df = pro.daily_basic(trade_date=backup_date_str, fields=fields)
        
    if df.empty: return pd.DataFrame()
    
    df['mv_äº¿'] = (df['circ_mv'] / 10000).round(2)
    return df[['ts_code', 'pe_ttm', 'pb', 'turnover_rate', 'mv_äº¿']]

def calculate_rps_logic(dates):
    df_now = get_snapshot(dates['now'])
    if df_now.empty: return None
    
    df_now.rename(columns={'close_val': 'base_now', 'display_val': 'price_now'}, inplace=True)
    
    final_df = df_now.copy()
    for n in RPS_N:
        if n not in dates: continue
        df_past = get_snapshot(dates[n])
        if df_past.empty: continue
        
        df_past = df_past[['ts_code', 'close_val']].rename(columns={'close_val': 'base_past'})
        temp = pd.merge(final_df, df_past, on='ts_code', how='left')
        
        temp[f'pct_{n}'] = (temp['base_now'] - temp['base_past']) / temp['base_past']
        temp[f'RPS_{n}'] = temp[f'pct_{n}'].rank(pct=True) * 100
        
        final_df = temp.drop(columns=['base_past'])
        
    return final_df

# ================= è¡Œä¸šè·å– =================

def get_industry_worker(code):
    try:
        symbol = code.split('.')[0] 
        df = ak.stock_individual_info_em(symbol=symbol)
        row = df[df['item'] == 'è¡Œä¸š']
        if not row.empty:
            return code, row['value'].values[0]
    except:
        pass
    return code, "-"

def fetch_detailed_industries(ts_codes):
    total = len(ts_codes)
    print(f"ğŸ­ [Akshare] å¯åŠ¨å¤šçº¿ç¨‹åŠ é€Ÿï¼Œæ­£åœ¨æŠ“å– {total} åªä¸ªè‚¡çš„ç»†åˆ†é¢˜æ...")
    industry_map = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        future_to_code = {executor.submit(get_industry_worker, code): code for code in ts_codes}
        count = 0
        for future in concurrent.futures.as_completed(future_to_code):
            code, industry = future.result()
            industry_map[code] = industry
            count += 1
            if count % 50 == 0: print(f"   ğŸš€ è¿›åº¦: {count}/{total}...")
    return industry_map

def process_history_and_change(new_df, file_path, date_str):
    """
    date_str: è¿™é‡Œå¿…é¡»ä¼ å…¥ã€çœŸå®çš„äº¤æ˜“æ—¥æœŸã€‘ï¼Œè€Œä¸æ˜¯ç³»ç»Ÿæ—¥æœŸ
    """
    history_map = {}
    yesterday_rps_map = {}
    today_change_map = {}
    
    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path)
            old_df['æ›´æ–°æ—¥æœŸ'] = old_df['æ›´æ–°æ—¥æœŸ'].astype(str)
            
            for _, row in old_df.iterrows():
                code = row['ts_code']
                last_update = row.get('æ›´æ–°æ—¥æœŸ', '')
                
                history_map[code] = {
                    'first': row.get('åˆæ¬¡å…¥é€‰', date_str),
                    'days': row.get('è¿ç»­å¤©æ•°', 0),
                    'last_update': last_update
                }

                # æ™ºèƒ½ç»§æ‰¿å˜åŠ¨å€¼é€»è¾‘
                if last_update == date_str:
                    if 'rps_50_chg' in row:
                        today_change_map[code] = row['rps_50_chg']
                else:
                    if 'RPS_50' in row:
                        yesterday_rps_map[code] = row['RPS_50']
                        
        except Exception as e:
            print(f"âš ï¸ è¯»å–å†å²æ–‡ä»¶å¾®ç‘•: {e}")

    res = []
    for _, row in new_df.iterrows():
        code = row['ts_code']
        first_date = date_str
        days_count = 1
        
        # è¿æ¿é€»è¾‘
        if code in history_map:
            hist = history_map[code]
            # å¦‚æœä¸Šæ¬¡æ›´æ–°æ—¥æœŸ == ä»Šå¤©çš„äº¤æ˜“æ—¥æœŸ -> è¯´æ˜ä»Šå¤©å·²ç»è·‘è¿‡ä¸€æ¬¡äº†ï¼Œå¤©æ•°ä¸åŠ 
            # å¦‚æœä¸Šæ¬¡æ›´æ–°æ—¥æœŸ != ä»Šå¤©çš„äº¤æ˜“æ—¥æœŸ -> è¯´æ˜æ˜¯æ–°çš„ä¸€å¤©äº¤æ˜“æ—¥ï¼Œå¤©æ•°+1
            if hist['last_update'] == date_str:
                days_count = hist['days']
                first_date = hist['first']
            else:
                days_count = hist['days'] + 1
                first_date = hist['first']
        
        row['åˆæ¬¡å…¥é€‰'] = first_date
        row['è¿ç»­å¤©æ•°'] = days_count
        
        # å˜åŠ¨å€¼é€»è¾‘
        if code in today_change_map:
            row['rps_50_chg'] = today_change_map[code]
        elif code in yesterday_rps_map:
            row['rps_50_chg'] = row['RPS_50'] - yesterday_rps_map[code]
        else:
            row['rps_50_chg'] = 999 
            
        # é›ªçƒé“¾æ¥
        if '.' in code:
            num, suffix = code.split('.')
            link_code = suffix.upper() + num 
            row['xueqiu_url'] = f"https://xueqiu.com/S/{link_code}"
        else:
            row['xueqiu_url'] = ""
            
        res.append(row)
    return pd.DataFrame(res)

def main_job():
    print("ğŸš€ å¯åŠ¨ Aè‚¡ RPS æ›´æ–° (V5.0 ä¸¥æ ¼äº¤æ˜“æ—¥ç‰ˆ)...")
    
    # è·å–ç³»ç»Ÿå½“å‰æ—¥æœŸ (YYYYMMDD)
    today_sys = datetime.datetime.now().strftime('%Y%m%d')
    
    # è·å–äº¤æ˜“æ‰€æ—¥å†ä¿¡æ¯
    dates = get_trading_dates(today_sys)
    if not dates: 
        print("âŒ æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œé€€å‡º")
        return
    
    trading_date = dates['now'] # è¿™æ˜¯äº¤æ˜“æ‰€çš„æœ€æ–°äº¤æ˜“æ—¥
    
    # â˜…â˜…â˜… æ ¸å¿ƒé—¨ç¦ï¼šå¦‚æœç³»ç»Ÿæ—¥æœŸ != äº¤æ˜“æ‰€æœ€æ–°æ—¥æœŸï¼Œè¯´æ˜ä»Šå¤©æ˜¯éäº¤æ˜“æ—¥ â˜…â˜…â˜…
    if today_sys != trading_date:
        print(f"ğŸ˜´ ä»Šå¤© ({today_sys}) ä¸æ˜¯äº¤æ˜“æ—¥ (æœ€æ–°äº¤æ˜“æ—¥: {trading_date})ã€‚")
        print("ğŸ›‘ è„šæœ¬åœæ­¢è¿è¡Œï¼Œä¿æŒæ•°æ®ä¸æ›´æ–°ï¼Œé˜²æ­¢è¿æ¦œå¤©æ•°è™šå¢ã€‚")
        return # ç›´æ¥ç»“æŸï¼

    # å¦‚æœé€šè¿‡é—¨ç¦ï¼Œè¯´æ˜ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œç»§ç»­æ‰§è¡Œ...
    print(f"âœ… ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ ({trading_date})ï¼Œå¼€å§‹æ‰§è¡Œè®¡ç®—...")
    
    # æ³¨æ„ï¼šåé¢æ‰€æœ‰çš„æ—¥æœŸå¼•ç”¨ï¼Œéƒ½å¿…é¡»ç”¨ trading_date (äº¤æ˜“æ‰€æ—¥æœŸ)ï¼Œè€Œä¸æ˜¯ç³»ç»Ÿæ—¥æœŸ
    # å°† YYYYMMDD è½¬ä¸º YYYY-MM-DD æ ¼å¼ç”¨äº CSV ä¿å­˜
    trading_date_fmt = f"{trading_date[:4]}-{trading_date[4:6]}-{trading_date[6:]}"

    os.makedirs("data", exist_ok=True)

    # 1. è®¡ç®— RPS
    df_stock = calculate_rps_logic(dates)
    
    if df_stock is not None:
        try:
            print("   åˆå¹¶åŸºç¡€æ•°æ®...")
            basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,industry')
            df_stock = pd.merge(df_stock, basic, on='ts_code', how='left')
            
            fina_df = get_fundamental_smart(dates['now'], dates.get('prev'))
            if not fina_df.empty:
                df_stock = pd.merge(df_stock, fina_df, on='ts_code', how='left')
            
            # 2. ç­›é€‰
            mask = (df_stock['RPS_50'] > THRESHOLD) & (df_stock['RPS_120'] > THRESHOLD) & (df_stock['RPS_250'] > THRESHOLD)
            strong_stock = df_stock[mask].copy()
            
            # â˜… è¿™é‡Œçš„æ›´æ–°æ—¥æœŸï¼Œä¸€å®šè¦ç”¨ã€äº¤æ˜“æ—¥æœŸã€‘ï¼Œè€Œä¸æ˜¯ç³»ç»Ÿæ—¥æœŸ
            strong_stock['æ›´æ–°æ—¥æœŸ'] = trading_date_fmt
            
            # 3. ç»†åˆ†è¡Œä¸š
            codes_list = strong_stock['ts_code'].tolist()
            if codes_list:
                industry_map = fetch_detailed_industries(codes_list)
                strong_stock['ç»†åˆ†è¡Œä¸š'] = strong_stock['ts_code'].map(industry_map)
                
                print("ğŸ”§ ä¿®è¡¥ç¼ºå¤±é¢˜æ...")
                strong_stock['ç»†åˆ†è¡Œä¸š'] = strong_stock['ç»†åˆ†è¡Œä¸š'].fillna('-')
                mask_missing = strong_stock['ç»†åˆ†è¡Œä¸š'] == '-'
                if 'industry' in strong_stock.columns:
                    strong_stock.loc[mask_missing, 'ç»†åˆ†è¡Œä¸š'] = strong_stock.loc[mask_missing, 'industry']
            else:
                strong_stock['ç»†åˆ†è¡Œä¸š'] = '-'
            
            # 4. å¤„ç†å†å² (ä¼ å…¥äº¤æ˜“æ—¥æœŸ)
            final_stock = process_history_and_change(strong_stock, STOCK_PATH, trading_date_fmt)
            
            # 5. ä¿å­˜
            base_cols = ['ts_code', 'name', 'ç»†åˆ†è¡Œä¸š', 'price_now', 'RPS_50', 'rps_50_chg', 'RPS_120', 'RPS_250', 'è¿ç»­å¤©æ•°']
            extra_cols = ['pe_ttm', 'mv_äº¿', 'turnover_rate', 'xueqiu_url', 'æ›´æ–°æ—¥æœŸ', 'åˆæ¬¡å…¥é€‰']
            
            save_cols = [c for c in base_cols + extra_cols if c in final_stock.columns]
            
            final_stock[save_cols].round(2).to_csv(STOCK_PATH, index=False)
            print(f"âœ… äº¤æ˜“æ—¥æ•°æ®æ›´æ–°å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("âš ï¸ æœªè·å–åˆ°è¡Œæƒ…æ•°æ®")

if __name__ == "__main__":
    main_job()
